from sentence_transformers import SentenceTransformer, InputExample, losses, models
from torch.utils.data import DataLoader
import os

# === Загружаем локальную модель ===
model_path = "E:/models/oldModal"  # Путь к локальной копии paraphrase-multilingual-MiniLM-L12-v2
word_embedding_model = models.Transformer(model_path)
pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())
model = SentenceTransformer(modules=[word_embedding_model, pooling_model])

# === Пример тренировочной выборки ===
# Формат: (текст1, текст2, метка), где метка 1.0 — похожие, 0.0 — непохожие
train_data = [
    # Похожие по смыслу (1.0)
    ("Спасибо! Всё чётко и понятно.", "Очень полезное видео!", 1.0),
    ("Объяснение на высоте. Благодарю!", "Спасибо, очень доходчиво объясняешь.", 1.0),
    ("Респект! Сделал всё по видео и работает.", "Супер гайд!", 1.0),
    ("Жаль, что поздно нашёл этот ролик.", "Благодарю! Всё работает!", 1.0),
    ("Отличная подача материала!", "Объяснение класс, всё работает!", 1.0),
    ("Спасибо большое за информацию.", "Благодаря тебе всё получилось.", 1.0),
    ("Слишком быстро говоришь", "Не успеваю уловить суть", 1.0),
    ("Не объяснил, откуда брать значения", "Пример не полный", 1.0),
    ("Что за ерунда?", "Где остальные части?", 1.0),
    ("Было бы здорово увидеть продолжение", "Жду вторую часть видео", 1.0),
    ("Ты крут, всё заработало!", "Лучший гайд, что видел!", 1.0),
    ("Разложил по полочкам", "Теперь всё ясно, спасибо!", 1.0),
    ("Говоришь непонятно", "Слишком сжато объясняешь", 1.0),
    ("Бесполезный ролик", "Ничего не работает", 1.0),
    ("Очень помогло, спасибо!", "Всё предельно ясно, круто!", 1.0),
    ("Объяснение отличное", "Всё по полочкам", 1.0),
    ("Давно искал такую инфу", "Наконец-то понятно стало", 1.0),
    ("У тебя талант к объяснению", "Лучшее объяснение, что видел", 1.0),
    ("Супер, понятно даже новичку", "Объясняешь как для детей – круто!", 1.0),
    ("Туториал бомба", "Видеоурок отличный", 1.0),
    ("Чётко и по делу", "Без лишней воды – супер!", 1.0),
    ("Видео очень полезное", "Спасибо за подробности!", 1.0),
    ("Автор красавчик", "Молодец, продолжай!", 1.0),
    ("Классный контент", "Годнота, лайк", 1.0),
    ("Хорошая озвучка", "Голос приятный", 1.0),
    ("Спасибо за труд", "Благодарю за полезную инфу", 1.0),
    ("Сделал всё по видео", "Всё вышло, круто!", 1.0),
    ("Очень крутой канал", "Подписался не глядя", 1.0),
    ("Ты мне очень помог", "Благодарю от души", 1.0),

    # Противоположные по смыслу (0.0)
    ("Спасибо за ролик", "Что за бред?", 0.0),
    ("Объяснение отличное", "Полный отстой", 0.0),
    ("Спасибо!", "Не понятно вообще", 0.0),
    ("Лучший туториал!", "Ничего не понял", 0.0),
    ("Подача хорошая", "Зачем это выкладывать?", 0.0),
    ("Всё заработало", "Ничего не работает", 0.0),
    ("Спасибо, ты спас!", "Ничего полезного", 0.0),
    ("Очень помогло", "Неполная информация", 0.0),
    ("Ролик супер", "Пустая трата времени", 0.0),
    ("Ты крут", "Автор некомпетентен", 0.0),
    ("Прекрасный туториал", "Всё объяснено ужасно", 0.0),
    ("Наконец-то понял", "Вообще не понял", 0.0),
    ("Благодарю, всё ясно", "Слишком сложно и запутанно", 0.0),
    ("Разложил по полочкам", "Каша из слов", 0.0),
    ("Чётко и по делу", "Слишком сжато и непонятно", 0.0),
    ("Туториал бомба", "Отвратительный гайд", 0.0),
    ("У тебя талант к объяснению", "Ты не умеешь объяснять", 0.0),
    ("Объясняешь как для детей – круто!", "Это для тупых?", 0.0),
    ("Лучшее объяснение, что видел", "Больше путаницы, чем пользы", 0.0),
    ("Очень крутой канал", "Удаляю подписку", 0.0),
    ("Голос приятный", "Озвучка раздражает", 0.0),
    ("Классный контент", "Контент мусорный", 0.0),
    ("Всё предельно ясно", "Сложно, непонятно", 0.0),
    ("Благодарю за инфу", "Ничего нового не узнал", 0.0),
    ("Ты мне очень помог", "Только потратил время", 0.0),
    ("Сделал всё по видео", "Невозможно повторить", 0.0),
    ("Хорошая озвучка", "Слушать невозможно", 0.0),
    ("Видео очень полезное", "Впустую потраченное время", 0.0),
];
# Преобразуем в InputExample
train_examples = [InputExample(texts=[a, b], label=label) for a, b, label in train_data]

# === Подготовка обучения ===
train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=8)
train_loss = losses.CosineSimilarityLoss(model)

# === Fine-tuning ===
model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=5,
    warmup_steps=10,
    show_progress_bar=True
)

# === Сохраняем обученную модель ===
output_path = "E:/models/newModal"
os.makedirs(output_path, exist_ok=True)
model.save(output_path)

print(f"\n✅ Обученная модель сохранена в: {output_path}")